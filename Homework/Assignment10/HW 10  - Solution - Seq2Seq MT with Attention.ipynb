{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64045f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf805e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8406414",
   "metadata": {},
   "source": [
    "Below are a few shorter problems. Please fill in the cells with your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2750a",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Given the example below, we have a bidirectional GRU. What is the connection between output and hidden? Explain in detail where exactly in output you can find hidden, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a318d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(1, 1, bidirectional=True, batch_first=True)\n",
    "\n",
    "# Use this same data for Problems 1 - 4\n",
    "x = torch.rand(4, 5, 1)\n",
    "\n",
    "# What is true about hidden and output? Where in output are the values in hidden? Be careful!\n",
    "output, hidden = gru(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b5e4d",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "The key is to realize that output has data like $(\\overrightarrow{h}_t, \\overleftarrow{h}_t)$ where $\\overrightarrow{h}$ and $\\overleftarrow{h}$ are respectively the forward and backward GRU's hidden states. Hidden, however, has the \"last\" hidden layer for each model. Specifically, for a sequence of length $T$, this is $(\\overrightarrow{h}_{T}, \\overleftarrow{h}_{1})$, becuase the forward model goes left to right while the back model goes right to left. I.e. you CANNOT take the last element of the output tensor state to get the same exact thing as the hidden tensor, you need to be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306f4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bf6ec8",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Consider the case when you have num_layers = 2 in a GRU as below. Describe what the conection now is between the hidden layer and the output layer. Specifically, what part of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96da8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(1, 1, num_layers=2, batch_first=True)\n",
    "\n",
    "# What is true about hidden and output? Where in output are the values in hidden? Be careful!\n",
    "output, hidden = gru(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401182c5",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Assume that the hidden layers are $\\overrightarrow{h}^{1, 2}_t$. The thing to realize here is that output contains just the representation (across time, for each batch) of all the second (output) hidden layers. This, output is really just $(\\overrightarrow{h}^{2}_1, \\ldots, \\overrightarrow{h}^{2}_T)$ assuming the batch is 1 and $T$ is the length of the data. On the other hand, hidden has in it $(\\overrightarrow{h}^{1}_{T}, \\overleftarrow{h}^{2}_{T})$, which is the final hidden representation of both the last (second) layer and the first layer. So, again, you cannot really connect a slice of the output with a slice of the returned hidden tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486f32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e4c88a",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Given Problem 2, write code to get the representation across all time steps $T$ of the first layer. I.e., write code below to get $(\\overrightarrow{h}^{1}_1, \\ldots, \\overrightarrow{h}^{1}_T)$. Do this for a GRU with two layers. Note that \"output\" does not have what you want - you need to be a little clever to get this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62183aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(1, 1, num_layers=2, batch_first=True)\n",
    "\n",
    "# What is true about hidden and output? Where in output are the values in hidden? Be careful!\n",
    "output, hidden = gru(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2e9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "# One easy way to do this is to do this is manually. Just have two GRUs and hae one's output feed into the other.\n",
    "# Then, loow through the named parameters of the gru and insert them into one or the other of the two grus above.\n",
    "from collections import OrderedDict\n",
    "\n",
    "gru1 = nn.GRU(1, 1, num_layers=1, batch_first=True)\n",
    "gru2 = nn.GRU(1, 1, num_layers=1, batch_first=True)\n",
    "\n",
    "sd1 = gru1.state_dict()\n",
    "sd2 = gru2.state_dict()\n",
    "sd = gru.state_dict()\n",
    "\n",
    "for name, param in sd.items():\n",
    "    if name in sd1:\n",
    "        sd1[name] = param\n",
    "    else:\n",
    "        name = name.split('_')\n",
    "        name[-1] = 'l0'\n",
    "        name = '_'.join(name)\n",
    "        sd2[name] = param\n",
    "        \n",
    "gru1.load_state_dict(sd1)\n",
    "gru2.load_state_dict(sd2)\n",
    "        \n",
    "# What is true about hidden and output? Where in output are the values in hidden? Be careful!\n",
    "output1, hidden1 = gru1(x)\n",
    "\n",
    "output2, hidden2 = gru2(output1)\n",
    "\n",
    "assert(torch.all(torch.eq(output, output2)))\n",
    "assert(torch.all(torch.eq(hidden, torch.vstack((hidden1, hidden2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b2755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90be4e86",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "In this problem we want to deal with sequences that are not the same length. Suppose we have 3 sequnces of data $a, b, c$, where the length of $a, b$ and $c$ are $2, 3$ and $4$ respectively. Assume you want to do a batch operation where the batch consists of $a, b$ and $c$ and you want to run these through the model. At the end, you'd like to get the final hidden state for each sentence. One way to do this is to pad all the sequences so they are length 4 and feed the 3 by 4 vector into the GRU.\n",
    "- What is the problem with doing this? What is ineffcient about it?\n",
    "- Investigate how to do this using the 4 imports below. You may not need all of these functions.\n",
    "- I.e. create a batch of size 3 containing the 3 tensors.\n",
    "- Pass this batch through the GRU.\n",
    "- Get the outputs, and print the last hidden states, as if you were passing through a, b and c manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ecd152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Each tensor is in (length, values) format\n",
    "a = torch.randn(2, 1)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.randn(4, 1)\n",
    "\n",
    "la, lb, lc = 2, 3, 4\n",
    "\n",
    "rnn = nn.RNN(1, 1, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7729b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "# One easy way to do this is to do this is manually. Just have two GRUs and hae one's output feed into the other\n",
    "# Then, low through the named parameters of the gru and insert them into one or the other of the two grus above\n",
    "# The main this is that if you pad and pass through, you always run data the same length through the rnn (for each row of the batch)\n",
    "# Imagine if one row has length 2 and one element of a batch has length 1000\n",
    "# Now, all these small length examples will still need to be processed 1000 steps, and almost all elements of output corresponding to their rows will be \"garbage\"\n",
    "\n",
    "seq = [a, b, c]\n",
    "\n",
    "padded = pad_sequence(seq, batch_first=True)\n",
    "\n",
    "packed1 = pack_padded_sequence(padded, lengths=[la, lb, lc], enforce_sorted=False, batch_first=True)\n",
    "# pack_padded_sequence is older, the below is a newer command\n",
    "packed2 = pack_sequence(seq, enforce_sorted=False)\n",
    "\n",
    "output_packed1, hidden_packed1 = rnn(packed1)\n",
    "output_packed2, hidden_packed2 = rnn(packed2)\n",
    "\n",
    "output_padded1, output_lengths1 = pad_packed_sequence(output_packed1, batch_first=True, total_length=4)\n",
    "output_padded2, output_lengths12= pad_packed_sequence(output_packed2, batch_first=True, total_length=4)\n",
    "\n",
    "assert(torch.all(torch.eq(output_padded1, output_padded2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90de6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf89df4",
   "metadata": {},
   "source": [
    "This example is like the previous one in HW 9, but now we want a more complicated model with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f38319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb58c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d0d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf61f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba853a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34d3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je suis fiance avec elle .', 'i am engaged to her .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958787f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Make the encoder a GRU and also make it bidirectional.\n",
    "        # Let it have 2 layers in the vertical direction.\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c75043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attention_projection = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.output_projection = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        # Make the GRU be unidirectional and also with 1 hidden layer\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # (1, 1, H)\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # (1, 2 * H)\n",
    "        # Concatenate yt and kt to get a vector (y_t, k_{t-1})\n",
    "        embedded_hidden = torch.cat((embedded[0], hidden[0]), 1)\n",
    "        \n",
    "        # (1, MAX_LENGTH)\n",
    "        # Project the above vector to get a vector mixing the elements of the above\n",
    "        # This vector will be used to get attention scores with all the encoder embeddings\n",
    "        # Here, the scores are scores = W_a[y_{t}, k_{t-1}] + b_a where W_a an b_a are in self.attention_projection\n",
    "        # You can have other formats here, but the one above is enough for this problem\n",
    "        attention_scores = self.attention_projection(embedded_hidden)\n",
    "        \n",
    "        # (1, MAX_LENGTH)\n",
    "        # Get the attention weights from the scores\n",
    "        attention_weights = nn.Softmax(dim=1)(attention_scores)\n",
    "        \n",
    "        # (1, 1, H)\n",
    "        # Multiply the weights by the hidden states (h_1, h_2, .., h_{T_x}) of the encoder\n",
    "        # This should be a vector of the above dimensions, so you'll need unsqueeze\n",
    "        # One way to do this is using torch.bmm on these unsqueezed vectors\n",
    "        # This will be the at vector that mixed the encoder's hidden representations; \"c_{t}\"\" in lecture\n",
    "        attention_context = torch.bmm(\n",
    "            attention_weights.unsqueeze(0),\n",
    "            encoder_outputs.unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        # (1, 2*H)\n",
    "        # Concatenate (yt, at) to get a vector that we will use to predict the output\n",
    "        output = torch.cat((embedded[0], attention_context[0]), 1)\n",
    "        \n",
    "        # (1, 1, H)\n",
    "        # Project the above vector into a new vector we'll use to predict with\n",
    "        output = self.output_projection(output).unsqueeze(0)\n",
    "\n",
    "        # (1, H)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # (1, H) and (1, H)\n",
    "        # Pass the output and hidden through the GRU. Note that we apply attention before we pass into the GRU\n",
    "        # This is a bit of the reverse from lecture\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        # (1, V)\n",
    "        # Either apply log_softmax to output or leave it alone\n",
    "        # This will have you use the NLLLoss or the CrossEntropyLoss\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attention_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4c517ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62e21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    target_length_used = 0\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        \n",
    "        target_length_used = target_length\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            \n",
    "            target_length_used += 1\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066a924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d194e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09179c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7adca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for it in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[it - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if it % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, it / n_iters),\n",
    "                                         it, it / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if it % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "            showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb3791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttentionDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc5c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5f5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                break                \n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da86763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f363235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=7500, debug=False):\n",
    "    bleu_scores = []\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        if debug:\n",
    "            print('French Original: ', pair[0])\n",
    "            print('English Reference: ', pair[1])\n",
    "        # Leave out the <EOS> symbol\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0])\n",
    "        \n",
    "        if 'EOS' == output_words[-1]:\n",
    "            output_words.pop()\n",
    "                                        \n",
    "        output_sentence = ' '.join(output_words)\n",
    "        score = 100.0 * sentence_bleu([pair[1].split(' ')], output_words, weights=[0.5, 0.5])\n",
    "        bleu_scores.append(score)\n",
    "        if debug:\n",
    "            print('Candidate Translation: ', output_sentence)\n",
    "            print('BLEU: ', score)\n",
    "            print('')\n",
    "    print('The mean BLEU score is: ', np.mean(bleu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cff40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861c69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
