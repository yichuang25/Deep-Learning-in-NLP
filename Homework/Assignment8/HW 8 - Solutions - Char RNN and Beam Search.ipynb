{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ab5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd215dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c0320b",
   "metadata": {},
   "source": [
    "### Get the data and process\n",
    "- This is the Mysterious island found in Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e64a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "## Reading and processing text\n",
    "with open('data/1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))\n",
    "assert(len(text) == 1130711)\n",
    "assert(len(char_set) == 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650c1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76393bdb",
   "metadata": {},
   "source": [
    "### Tokenze and get other helpers\n",
    "- We do this manually since everything is character based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a445114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "# The universe of words.\n",
    "chars_sorted = sorted(char_set)\n",
    "\n",
    "# Effectively, these maps are the tokenizer.\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "int2char = np.array(chars_sorted)\n",
    "\n",
    "# Tokenize the entire corpus.\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(int2char[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcafe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c418ca0",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb989c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e0421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.3M\thw7_model.pt\r\n"
     ]
    }
   ],
   "source": [
    "!du -h hw7_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f05f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lost a traced version of this model.\n",
    "# Note this is the same as the HW 7 model but a little different\n",
    "# The HW7 model had an if-else in its forward method, and this is not allowed.\n",
    "# The forward method of this model takes hidden and cell, which could be all zeros but the user has to specify.\n",
    "model = torch.jit.load('hw7_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f09c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([85, 256])\n",
      "rnn.weight_ih_l0 torch.Size([2048, 256])\n",
      "rnn.weight_hh_l0 torch.Size([2048, 512])\n",
      "rnn.bias_ih_l0 torch.Size([2048])\n",
      "rnn.bias_hh_l0 torch.Size([2048])\n",
      "fc.weight torch.Size([85, 512])\n",
      "fc.bias torch.Size([85])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbff927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=RNN\n",
       "  (embedding): RecursiveScriptModule(original_name=Embedding)\n",
       "  (rnn): RecursiveScriptModule(original_name=LSTM)\n",
       "  (fc): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f58492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'jit' does not save other methods on a model, we need to define this helper and use it below.\n",
    "def init_hidden(model, batch_size):\n",
    "    return (\n",
    "        torch.zeros(1, batch_size, model.rnn_hidden_size),\n",
    "        torch.zeros(1, batch_size, model.rnn_hidden_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0764392a",
   "metadata": {},
   "source": [
    "### Beam search algorithm.\n",
    "- Good article: https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28c6218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoding(\n",
    "    model,\n",
    "    starting_str, \n",
    "    len_generated_text=500, \n",
    "    beams=5,\n",
    "    print_paths=True\n",
    "):\n",
    "    assert(len(starting_str) != 0)\n",
    "\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    \n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Unfortunately, jit save does not save methods other than forward.\n",
    "    hidden, cell = init_hidden(model, 1)\n",
    "    \n",
    "    hidden = hidden.to(device)\n",
    "    \n",
    "    cell = cell.to(device)\n",
    "    \n",
    "    generated_log_prob = 0\n",
    "    generated_str = starting_str[0]\n",
    "        \n",
    "    # Build up the starting hidden and cell states.\n",
    "    # You can do this all in one go?\n",
    "    for i in range(len(starting_str)-1):\n",
    "        # Feed each letter 1 by 1 and then get the final hidden state.\n",
    "        out = encoded_input[:, i].reshape(1, 1)\n",
    "        logits, (hidden, cell) = model(out, hidden, cell)\n",
    "        \n",
    "        # Get the probability of the generated character.\n",
    "        # For input of index i, we want the probability that the model generated i+1.\n",
    "        # We push the startiing_str[i] into the model, and append starting_str[i+1] to generated_str.\n",
    "        generated_str += starting_str[i+1]\n",
    "        \n",
    "        probs = nn.Softmax(dim=1)(logits.squeeze(1)).squeeze()\n",
    "        \n",
    "        # P(y_{t} | y_{t-1}, y_{t-2}, ..., y_{1})\n",
    "        generated_log_prob += np.log(\n",
    "            probs[\n",
    "                char2int[generated_str[i+1]]\n",
    "            ].item()\n",
    "        )\n",
    "        \n",
    "    last_char_int = encoded_input[:, -1].reshape(1,1)\n",
    "    \n",
    "    logits, (hidden, cell) = model(last_char_int, hidden, cell)\n",
    "                        \n",
    "    probs = nn.Softmax(dim=1)(logits.squeeze(1)).squeeze()\n",
    "    \n",
    "    new_beams = []\n",
    "    \n",
    "    for j, prob in enumerate(probs):\n",
    "        new_beams.append(\n",
    "            (\n",
    "                hidden,\n",
    "                cell,\n",
    "                generated_str + int2char[j],\n",
    "                generated_log_prob + np.log(prob.item())\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Sort the beams from most proable to least. Use -log(p).\n",
    "    new_beams = sorted(new_beams, key = lambda beam_data: -beam_data[-1])\n",
    "    \n",
    "    beam_to_beam_data = {}\n",
    "    \n",
    "    for beam in range(beams):\n",
    "        beam_to_beam_data[beam] = new_beams[beam]\n",
    "    \n",
    "    print('The number of beams is', len(beam_to_beam_data))\n",
    "        \n",
    "    for i in range(len_generated_text):\n",
    "        new_beams = []\n",
    "        \n",
    "        for beam in range(beams):\n",
    "            \n",
    "            (hidden, cell, generated_str, generated_log_prob) = beam_to_beam_data[beam]\n",
    "                        \n",
    "            last_char_int = torch.tensor(char2int[generated_str[-1]]).reshape(1, 1)\n",
    "            \n",
    "            logits, (hidden, cell) = model(last_char_int, hidden, cell)\n",
    "            \n",
    "            probs = nn.Softmax(dim=1)(logits.squeeze(1)).squeeze()\n",
    "                                                \n",
    "            for j, prob in enumerate(probs):\n",
    "                new_beams.append(\n",
    "                    (\n",
    "                        hidden,\n",
    "                        cell,\n",
    "                        generated_str + int2char[j],\n",
    "                        generated_log_prob + np.log(prob.item())\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # Sort the beams from most proable to least. Use -log(p).\n",
    "        new_beams = sorted(new_beams, key = lambda beam_data: -beam_data[-1])\n",
    "                \n",
    "        # The number of beams considered should always satisfy this.\n",
    "        # Except for the first iteration.\n",
    "        assert(len(new_beams) == beams * len(char2int))\n",
    "        \n",
    "        if print_paths:\n",
    "            print(\"The first 5 paths beam paths and the associated data for them: \")\n",
    "            for beam in range(5):\n",
    "                generated_str, generated_log_prob = new_beams[beam][2:]\n",
    "                print(\"Text: \\\"{}\\\" Prob {:0.30f}\".format(\n",
    "                        generated_str, np.exp(generated_log_prob)\n",
    "                ))\n",
    "            _ = input(\"Insert anything to continue ...\")\n",
    "            print(\"\\n\")\n",
    "                \n",
    "        # Update the beams to be equal to the top beams.\n",
    "        for beam in range(beams):\n",
    "            beam_to_beam_data[beam] = new_beams[beam]\n",
    "            \n",
    "    generated_strs = []\n",
    "    generated_log_probs = []\n",
    "        \n",
    "    for beam in range(beams):\n",
    "        (_, _, generated_str, generated_log_prob) = beam_to_beam_data[beam]\n",
    "        generated_strs.append(generated_str)\n",
    "        generated_log_probs.append(generated_log_prob)        \n",
    "                \n",
    "    return generated_strs, [np.exp(_) for _ in generated_log_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of beams is 5\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, \" Prob 0.000520035624382387119506165885\n",
      "Text: \"The island w\" Prob 0.000227799324636454402067883840\n",
      "Text: \"The island?”\" Prob 0.000097528783550422128417051182\n",
      "Text: \"The island o\" Prob 0.000093910921207016688472789256\n",
      "Text: \"The island i\" Prob 0.000063718712271929359939465209\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island wa\" Prob 0.000172444312622175221702547354\n",
      "Text: \"The island, w\" Prob 0.000092942431504603877394019018\n",
      "Text: \"The island, a\" Prob 0.000090473014760760145456380821\n",
      "Text: \"The island, t\" Prob 0.000070329177943556804835506524\n",
      "Text: \"The island?”\n",
      "\" Prob 0.000062701887612621581271840632\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island was\" Prob 0.000168390777398385932048241465\n",
      "Text: \"The island, an\" Prob 0.000071394498489104718345898970\n",
      "Text: \"The island, th\" Prob 0.000063585879998671285631174632\n",
      "Text: \"The island?”\n",
      "\n",
      "\" Prob 0.000062353845602206221278296372\n",
      "Text: \"The island, wh\" Prob 0.000055470405798159414239179715\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island was \" Prob 0.000162886606720045377895075833\n",
      "Text: \"The island, and\" Prob 0.000070901871302145183864618083\n",
      "Text: \"The island?”\n",
      "\n",
      "“\" Prob 0.000043470926973089517287261729\n",
      "Text: \"The island, the\" Prob 0.000041231253030852359447826216\n",
      "Text: \"The island, who\" Prob 0.000031136489860345885078568573\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and \" Prob 0.000066633783205592716928147845\n",
      "Text: \"The island, the \" Prob 0.000022295299832291799502258581\n",
      "Text: \"The island was s\" Prob 0.000017944534091877657413669975\n",
      "Text: \"The island, who \" Prob 0.000017057419277832911098284965\n",
      "Text: \"The island was n\" Prob 0.000016321604081065519287890853\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and t\" Prob 0.000017958413385247575487502214\n",
      "Text: \"The island was no\" Prob 0.000013530790669816228095206911\n",
      "Text: \"The island was st\" Prob 0.000005924833556669433614597000\n",
      "Text: \"The island, and w\" Prob 0.000005824252658846007486099713\n",
      "Text: \"The island, and i\" Prob 0.000005722347216996238228770445\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and th\" Prob 0.000016443975701748143831764856\n",
      "Text: \"The island was not\" Prob 0.000011276356243426131187963454\n",
      "Text: \"The island, and it\" Prob 0.000004401433172553300938003359\n",
      "Text: \"The island was sti\" Prob 0.000002779730699933294694564364\n",
      "Text: \"The island, and wh\" Prob 0.000001813159164891349237427355\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and the\" Prob 0.000010454561324388920813739136\n",
      "Text: \"The island was not \" Prob 0.000009205853143359940922918136\n",
      "Text: \"The island, and it \" Prob 0.000004100519059773806692455363\n",
      "Text: \"The island, and tha\" Prob 0.000003410578967898756639666197\n",
      "Text: \"The island was stil\" Prob 0.000002749086953532576696961716\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and the \" Prob 0.000005812341588656687606283605\n",
      "Text: \"The island, and that\" Prob 0.000003384754893271053863865010\n",
      "Text: \"The island, and it w\" Prob 0.000003218232509092679415198908\n",
      "Text: \"The island was still\" Prob 0.000002747602888444652123237479\n",
      "Text: \"The island, and they\" Prob 0.000001530513553523463538271290\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and that \" Prob 0.000003094642141189091489450599\n",
      "Text: \"The island was still \" Prob 0.000002619106736716375068125357\n",
      "Text: \"The island, and it wa\" Prob 0.000002332773044231238275048653\n",
      "Text: \"The island, and they \" Prob 0.000001463769443847624681070540\n",
      "Text: \"The island, and the s\" Prob 0.000000840401564178404399010729\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was\" Prob 0.000002320178706958571389541322\n",
      "Text: \"The island, and that t\" Prob 0.000001036602955026826357535076\n",
      "Text: \"The island was still t\" Prob 0.000000548208028420043747882672\n",
      "Text: \"The island, and that i\" Prob 0.000000465098739820374471948738\n",
      "Text: \"The island, and they w\" Prob 0.000000397745411641401459637183\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was \" Prob 0.000002180166153715842196120136\n",
      "Text: \"The island, and that th\" Prob 0.000000995319539659070688414517\n",
      "Text: \"The island was still th\" Prob 0.000000319189288014528414445732\n",
      "Text: \"The island, and that is\" Prob 0.000000311662237480900190940528\n",
      "Text: \"The island, and they we\" Prob 0.000000187845091326499898787741\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and that the\" Prob 0.000000811750143478994685318972\n",
      "Text: \"The island, and it was n\" Prob 0.000000460739898664555668927770\n",
      "Text: \"The island, and it was t\" Prob 0.000000319451532426685134984253\n",
      "Text: \"The island, and that is \" Prob 0.000000243904837724117802866432\n",
      "Text: \"The island was still the\" Prob 0.000000200740499643505534539342\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and that the \" Prob 0.000000567758523085180477499388\n",
      "Text: \"The island, and it was th\" Prob 0.000000259080082931205728881191\n",
      "Text: \"The island, and it was no\" Prob 0.000000249608922243417446709549\n",
      "Text: \"The island, and it was ne\" Prob 0.000000203408416592748565312351\n",
      "Text: \"The island, and that is t\" Prob 0.000000162549003773046597461793\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was not\" Prob 0.000000223617078250826203708110\n",
      "Text: \"The island, and it was the\" Prob 0.000000194868010696914758678606\n",
      "Text: \"The island, and it was nec\" Prob 0.000000158633607752939597517313\n",
      "Text: \"The island, and that is to\" Prob 0.000000140876502146442485525441\n",
      "Text: \"The island, and that the s\" Prob 0.000000091168985280911766032845\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was not \" Prob 0.000000193269857724836685658546\n",
      "Text: \"The island, and it was nece\" Prob 0.000000157542967282346663189670\n",
      "Text: \"The island, and that is to \" Prob 0.000000127731702197862290253818\n",
      "Text: \"The island, and it was the \" Prob 0.000000082838013607620644308573\n",
      "Text: \"The island, and it was ther\" Prob 0.000000054961793308572583590739\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was neces\" Prob 0.000000156560949262643312743647\n",
      "Text: \"The island, and it was there\" Prob 0.000000053867963854688683617974\n",
      "Text: \"The island, and that is to s\" Prob 0.000000042620285320625669595069\n",
      "Text: \"The island, and it was not a\" Prob 0.000000026380103147166685645907\n",
      "Text: \"The island, and that is to b\" Prob 0.000000023313432578693227640123\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was necess\" Prob 0.000000155033162885432141675219\n",
      "Text: \"The island, and that is to sa\" Prob 0.000000036562188382879102302289\n",
      "Text: \"The island, and that is to be\" Prob 0.000000020992617679836261914198\n",
      "Text: \"The island, and it was there \" Prob 0.000000020359625587574133965769\n",
      "Text: \"The island, and it was theref\" Prob 0.000000018491415090513583285269\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was necessa\" Prob 0.000000153320353566732866362597\n",
      "Text: \"The island, and that is to say\" Prob 0.000000030447655711683079289243\n",
      "Text: \"The island, and it was therefo\" Prob 0.000000018402059621512165985046\n",
      "Text: \"The island, and that is to be \" Prob 0.000000015369679100027869302418\n",
      "Text: \"The island, and it was there w\" Prob 0.000000006263265649167558396804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was necessar\" Prob 0.000000152024380545919445244178\n",
      "Text: \"The island, and it was therefor\" Prob 0.000000018085692396889703460052\n",
      "Text: \"The island, and that is to say,\" Prob 0.000000013691599299554593781165\n",
      "Text: \"The island, and that is to say \" Prob 0.000000013242337464759689322885\n",
      "Text: \"The island, and it was there wa\" Prob 0.000000002904640619469246882912\n",
      "Insert anything to continue ...\n",
      "\n",
      "\n",
      "The first 5 paths beam paths and the associated data for them: \n",
      "Text: \"The island, and it was necessary\" Prob 0.000000150955421062497408813248\n",
      "Text: \"The island, and it was therefore\" Prob 0.000000017986524745911925254024\n",
      "Text: \"The island, and that is to say, \" Prob 0.000000010136494858898432154721\n",
      "Text: \"The island, and that is to say t\" Prob 0.000000006149802997271163963106\n",
      "Text: \"The island, and it was there was\" Prob 0.000000002887440146783889264895\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "model.to('cpu')\n",
    "beams=5\n",
    "len_generated_text=500\n",
    "\n",
    "generated_strs, generated_probs = beam_search_decoding(\n",
    "    model,\n",
    "    starting_str=\"The island\",\n",
    "    len_generated_text=len_generated_text,\n",
    "    beams=beams\n",
    ")\n",
    "\n",
    "for beam in range(beams):\n",
    "    print(f\"Beam {beam} information: \")\n",
    "    print(generated_strs[beam])\n",
    "    print(generated_probs[beam])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bec4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a540b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47d254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f55d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e7b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
